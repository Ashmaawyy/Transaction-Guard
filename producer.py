import time
import json
import random
from kafka import KafkaProducer
from faker import Faker
from datetime import datetime, timedelta
from utils.model import Transaction # Assuming model.py is in the same directory

# --- Configuration ---
KAFKA_BROKER = 'localhost:9092' # Matches the advertised listener in docker-compose
KAFKA_TOPIC = 'financial_transactions'
SLEEP_TIME_SECONDS = 0.1 # High frequency stream (10 events per second)
NUM_USERS = 500 # Simulate transactions for 500 unique users
MAX_AMOUNT = 500.00

# Initialize Faker
fake = Faker()

# --- Kafka Setup ---
# Initialize the Kafka Producer
# Use json.dumps as the value serializer to send structured data
producer = KafkaProducer(
    bootstrap_servers=[KAFKA_BROKER],
    value_serializer=lambda v: json.dumps(v).encode('utf-8'),
    # Optional: ensure message delivery
    acks='all',
    retries=3
)

# --- Utility Functions ---

def generate_user_id():
    """Generates a random user ID for the transaction."""
    # Use consistent, but randomized IDs to simulate repeat users
    return random.randint(100000, 100000 + NUM_USERS)

def generate_transaction_data(user_id: int) -> dict:
    """
    Creates a single transaction event dictionary compliant with the Pydantic schema.
    """
    
    # 90% of transactions are normal, 10% are potential "fraud" (high amount or unusual location)
    is_normal = random.random() < 0.90
    
    # Simulate a user's location (focus on US, Europe, or Asia)
    if is_normal:
        # Normal transaction: small amount, standard location
        lat = fake.latitude()
        lon = fake.longitude()
        amount = round(random.uniform(1.00, 150.00), 2)
    else:
        # Potential fraud simulation: very high amount, or location far from previous (Spark will check this)
        lat = fake.latitude() * random.uniform(0.5, 1.5) # Slight deviation
        lon = fake.longitude() * random.uniform(0.5, 1.5)
        amount = round(random.uniform(MAX_AMOUNT * 0.5, MAX_AMOUNT * 2.0), 2)
        
    
    # Use the Pydantic model for strict validation before sending
    try:
        transaction = Transaction(
            user_id=user_id,
            amount=amount,
            merchant_id=fake.company(),
            latitude=lat,
            longitude=lon
            # The transaction_id and timestamp_ms fields are auto-generated by the model defaults
        )
        return transaction.dict()
    except Exception as e:
        print(f"Schema Validation Error: {e}")
        return None


# --- Main Loop ---

print(f"--- Starting Transaction Producer to {KAFKA_TOPIC} on {KAFKA_BROKER} ---")

try:
    while True:
        # Simulate a transaction for a random user
        user = generate_user_id()
        data = generate_transaction_data(user)
        
        if data:
            # Send the transaction data to Kafka
            future = producer.send(
                topic=KAFKA_TOPIC, 
                key=str(user).encode('utf-8'), # Key by User ID for partitioning
                value=data
            )
            
            # Optional: Log success/failure
            # result = future.get(timeout=10)
            
            print(f"[{datetime.now().strftime('%H:%M:%S')}] Sent Txn {data['transaction_id']} (User: {data['user_id']}, Amount: ${data['amount']})")

        time.sleep(SLEEP_TIME_SECONDS)

except KeyboardInterrupt:
    print("\nProducer stopped by user.")
except Exception as e:
    print(f"An error occurred: {e}")
finally:
    producer.flush()
    producer.close()
    print("Kafka Producer closed.")